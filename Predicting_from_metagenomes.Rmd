---
title: "Host trait prediction from high-resolution microbial features"
author: "Giovanni Bacci^1^*  \n^1^Department of Biology, University of Florence, Via Madonna del Piano 6, Sesto Fiorentino, FI, I-50019, Italy  \n*Corresponding author: giovanni.bacci@unifi.it"
output: word_document
bibliography: ./bib/bibliography.bib
csl: ./bib/springer-basic-brackets-no-et-al.csl
---

```{r setup, include=FALSE}
library(DESeq2)
library(compositions)
library(vegan)
library(caret)
library(pROC)
library(tidyverse)
library(ggbeeswarm)
library(patchwork)
library(multcompView)

knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      eval = TRUE)
```

## Running head

Predictions from metagenomes

## Summary (500 characters)

Predicting host traits from metagenomes presents new challenges that can be difficult to overcome for researchers without a strong background in bioinformatics and/or statistics. Profiling bacterial communities using shotgun metagenomics often leads to the generation of a large amount of data that cannot be used directly for training a model. In this chapter we provide a detailed description of how to build a working machine learning model based on taxonomic and functional features of bacterial communities inhabiting the lungs of cystic fibrosis patients. Models are build in the R environment by using different freely available machine learning algorithms.

## Keywords

machine learning, next generation sequencing, metagenomics, host trait prediction, community profiling, taxonomic profiling, functional profiling

## 1. Introduction

Metagenomics---the direct extraction and sequencing of genetic material from bacterial cells inhabiting a given environment---has drastically increased our knowledge of the microbial world. Since the first study made by Antonie van Leeuwenhoek in 1680s where he compared microorganisms from fecal and oral samples of healthy and ill individuals [@van14abstract] microbiologists have characterized thousands of different microbial strains in, almost, all districts of human body [@Turnbaugh2007; @NIHGroup01122009; @LloydPrice2017]. The interaction between plants and microorganisms has been intensively explored during the last twenty years, shading light on new possible methods of cultivation and defining groups of microorganisms associated with plant health [@Lundberg2012]. In 2001 Joshua Lederberg coined the term microbiome referring to “the ecological community of commensal, symbiotic, and pathogenic microorganisms that literally share our body space” [@lederberg2001ome]; but in more recent times researchers have used the same term to refer to other types of macroorgansims such arthropods, fish, and plants. Many studies have been performed in animals and plants, reporting the description of the bacterial communities (microbiome) found in several districts as gut, roots, skin, and leafs [@hyde2013living; @stoll2007bacterial; @berlec2012novel].

In the last decade the sequencing cost for a magabase of DNA has dropped while the output of sequencing machines has rapidly increased. The advent of third-generation sequencing technologies (also known as long-read sequencing) has enabled the production of long DNA sequences from single DNA molecules increasing the resolution power of 'omics techniques including Metagenomics, but all these technical advancements requires the development of specific analysis methods suitable for different applications. Several methods have been developed to cope with this humongous amount of data, all dealing with sequence information that can be retrieved from public database (extrinsic approaches) or directly from sequences themselves (intrinsic approaches). These methods (almost) always produce abundance matrices describing different aspects of the bacterial community under study, depending on the analytic approach used. In this chapter we are going to use two matrices reporting the abundance of bacterial taxa and genes detected in the lung of cystic fibrosis patients to inspect the link between host traits (i.e. the type of mutation in the CFTR gene) and microbial characteristics.

## 2. Materials

This tutorial requires a working installation of R [@rcore2019] along with a set of additional libraries mainly used for building and validating our final model. The workflow here proposed uses data coming from a metagenomic study on cystic fibrosis lung communities along time [@bacci2020tax]. A complete description of datasets, hardware and software requirements is given below.

### 2.1 Data files

We will build a machine learning model based on bacterial features obtained from shotgun metagenomics sequencing. The data consist of three main tables reporting quantitative and qualitative information about taxa detected in the lung of subjects included in the study, genes harbored by those taxa, and clinical characteristics of the subjects. Data can be downloaded from [https://github.com/GiBacci/predicting_from_metagenomes/tree/master/data](https://github.com/GiBacci/predicting_from_metagenomes/tree/master/data). Tables are available in the RDS format and can be easily imported into R using the function `readRDS()`. Since RDS is a native data R file format, we can loaded tables directly into the R environment without worrying about additional parameters such as field separator, decimal separator, character encoding format, and so on. A description of the data files is reported below:

1. taxa_ab.rds: taxa abundances in all subjects included in the study. Each row of the table is a different observation whereas each column represent a different taxa detected. The proportion of taxa is reported as relative abundance so that the sum of all taxa abundances in each observation is one.
   
2. gene_counts.rds: counts of metagenomic reads mapping to bacterial genes recovered from lung communities. The same standard used for taxa abundance was used here with each row reporting a different observation and each column reporting a different gene. In metagenomic studies genes are usually more than observations and they can be reported as rows instead of columns so to minimize the number of variables and reduce memory requirement.

3. sample_meta.rds: characteristics of patients included in the study. The table is the table S1 of the paper reported above [@bacci2020tax] and a complete description of columns is available in the work. In this chapter we will focus on the genotype of the patients aiming at building a machine learning algorithm that can predict a patient's genotype from bacterial features.
   
3. gene_meta.rds: characteristics of genes included in the gene count table reported in 2. This table is a slight modified version of the output produced by eggNOG mapper [@huerta2017fast]. 

In principle any kind of metagenomics/transcriptomics study follow the scheme here proposed. The table reported in 1 and/or 2 could be replaced by the expression levels of genes found in a transcriptomic study or by counts of reads coming from a metabarcoding study based on 16S rRNA sequencing. Feel free to replace the tables reported above with any kind of data that fit the general scheme provided.

### 2.2 Software requirements

Models are generated using a free software environment for statistical computing called R. R is part of many Linux distributions but it can be freely downloaded and installed from [https://cran.r-project.org/](https://cran.r-project.org/) by choosing the appropriate operation system in the "Download and Install R" window. Additional packages needed are listed below (the version of each package used in this tutorial is reported between brackets):

1. compositions [@vandenboogaart2008comp] (version `r  packageVersion("compositions")`): a collection of functions for analyzing compositional data (quantitative data, strictly positive, which sum to a constant value).
   
2. vegan [@oksanen2019vegan] (version `r  packageVersion("vegan")`): a package developed for studying multivariate data produced during ecological studies. It contains several functions for dimensionality reduction (such as correspondence analysis, non-metric multidimensional scaling, and others) and for diversity analysis (either alpha or beta diversity).

3. DESeq2 [@love2014moderated] (version `r  packageVersion("DESeq2")`): a suite for the analysis of count data from many biological assays. The package was developed for analyzing RNA-seq data but it is also used for amplicon sequence data (such as 16S rRNA metabarcoding) or ChIP-Seq. It implements a transformation function (called variance stabilizing transformation or VST) useful to prepare count data for machine learning approaches.

4. caret [@kuhn2015caret] (version `r  packageVersion("caret")`): a collection of functions for training and validating multiple machine learning algorithms. It contains methods for fine tuning classification and regression algorithms using a unified syntax. It also evaluates the performance of models produced using standard metrics such as root mean squared error, receiver operating characteristic curve, and accuracy.

5. randomForest [@liaw2002class] (version `r  packageVersion("randomForest")`): implementation of the random tree forest algorithm described by Breiman in 2001 [@breiman2001random]. This package is used in combination with caret to build the final model.

6. kernlab [@karatzoglou2004kern] (version `r  packageVersion("kernlab")`): implementation of the most used kernel-based machine learning methods [@scholkopf2001learn]. In this chapter we will use the radial basis function kernel in combination with caret.

7. gbm [@greenwell2019gbm] (version `r  packageVersion("gbm")`): implementation of gradient boosting machines. A stochastic gradient boosting approach will be used within caret. 

6. pROC [@robin2011proc] (version `r  packageVersion("pROC")`): tool for visualizing receiver operating characteristic (ROC) curves. It contains also functions for comparing curves from different models. Curves are computed in sensitivity and specificity space defined as the probability to assign a true positive or a false negative given the model.

7. ggplot2 [@wickham2016ggplot2] (version `r  packageVersion("ggplot2")`): package for creating different types of graphics based on the book "The grammar of Graphics" by Leland Wilkinson [@wilkinson2012grammar].

8. ggbeeswarm [@clarke2017ggbee] (version `r  packageVersion("ggbeeswarm")`): this package provides ggplot2 geoms for plotting categorical data minimizing overlaps.

9. multcompView [@graves2019mult] (version `r  packageVersion("multcompView")`): package that converts vectors of p-values into a letter-based visualization useful for multiple comparisons across categories.

## 3. Methods

A working installation of R can run all lines of code reported in this chapter. However, I would suggest to write codes into a script (a simple text file) by using an integrated development environment (IDE) like RStudio [https://rstudio.com/](https://rstudio.com/).

### 3.1 Importing data

Before starting to build our models data must be imported into R. Several functions can do this depending on the input file format. The data suggested in this chapter were saved using a native R format called RDS and can be imported using the `readRDS` function. In case of text data the function `read.table` can be used as well as one of its sister functions (to see the help of `read.table` simply run: `?read.table`).

```{r dataImport}
# importing gene counts
genes <- readRDS("./data/gene_counts.rds")

# importing proportion of taxa
taxa <- readRDS("./data/taxa_ab.rds")

# sample data
meta <- readRDS("./data/sample_meta.rds")
```

### 3.2 Data transformation

As described in section 2.1, our data consist of three tables---two of which were imported into R as "matrix" that is still a type of tabular format---reporting different features of a specific bacterial community: the lung of patients affected by cystic fibrosis. Data reported in these tables, however, differ from a statistical/mathematical point of view. For example, the 'taxa' table  reports abundances of bacterial organisms expressed as relative abundances or, in other words, as fractions. On the other hand, the 'gene' table contains counts of reads mapped to specific genes and the 'meta' table contains information about each patient included in the original study.

Quantitative data must be handled in the proper way to generate reliable results. Relative abundance data (also called "compositional data") are constrained so that their sum must be a constant (e.g. one in the case of relative abundances and 100 in the case of percentages). The sample space for this kind of data differs from the real space associated with unconstrained data [@aitchison1983principal] resulting in an excess of negative correlations. This influences standard statistical multivariate analyses where the abundance of different taxa may be positively or negatively correlated [@lovell2015prop]. In addition, machine learning algorithms may benefit from reducing the number of correlated predictors as well as reducing the number of type I errors [@ijms18081654; @John864]. Counts of reads obtained through high-throughput sequencing machines, on the other hand, are usually overdispersed (they have a variance much larger than the mean) and contain a high proportion of zero counts (sparsity). Besides, the total number of sequences obtained for a given sample does not match the real number of microbes present in that sample. Since the number of reads produced by modern sequencing machines is constrained by the capacity of the instrument, counts of microbial features can be considered compositional and thus constrained to sum to a given constant [@weiss2017norm]. All these problems are still debated in the scientific community especially regarding the study of bacterial community.

Taxa abundances will be transformed using centered log ratio transformation (CLR) whereas gene counts will be transformed using the so called variance stabilizing transformation (VST) provided in the DESeq2 package. Both transformations may help subsequent multivariate analyses such as principal component analysis (PCA) reducing the number of negative correlation (CLR) and the variance (VST). Both datasets will be converted into orthogonal predictors using PCA to reduce type I errors (as explained above) prior to feed machine learning models. Only principal components with an eigenvalue higher than one will be retained. We will feed our model also with an alpha diversity index (namely the inverse Simpson index) to test the importance of bacterial diversity in predicting patient genotype.

```{r dataTransformation}
# Centered log ratio transformation
taxa.clr <- clr(taxa)
class(taxa.clr) <- "matrix"

# Variance stabilizing transformation
genes.vst <- DESeqDataSetFromMatrix(t(genes), colData = meta, design = ~ 1)
genes.vst <- estimateSizeFactors(genes.vst)
genes.vst <- vst(genes.vst, blind = TRUE, fitType = "local")
genes.vst <- t(assay(genes.vst))

# Alpha diversity estimation
alpha <- diversity(taxa, index = "invsimpson")
alpha <- data.frame(A=(alpha - mean(alpha))/sd(alpha))

# Principal component analysis
taxa.pca <- prcomp(taxa.clr, center = T, scale. = T)
genes.pca <- prcomp(genes.vst, center = T, scale. = T)

# Retaining only PC with an eigenvalue higher than one
taxa.x <- taxa.pca$x[,taxa.pca$sdev^2 >= 1]
genes.x <- genes.pca$x[,genes.pca$sdev^2 >= 1]

# Assembling the full dataset
colnames(taxa.x) <- gsub("PC", "T", colnames(taxa.x))
colnames(genes.x) <- gsub("PC", "F", colnames(genes.x))

y <- meta$genotype
full.data <- cbind(y = y, taxa.x, genes.x, alpha)
full.data <- droplevels(full.data[full.data$y != "other",])
```

### 3.2 Training models

In this section, we are going to train three different machine learning models using caret and the respective machine learning packages defined in section 2.2. The function `set.seed` ensures reproducibility during random operations such as splitting our dataset into validation and training set. Data will be partitioned into a training set, used for training the models, and a validation set, for testing them. Machine learning algorithms need to be tuned in order to function correctly. The number and the type of parameters varies in each algorithm so it is recommended to chose the best value programmatically. The so called cross-validation process attempts to do that by validating different parameters on a subset of the training set previously defined. The caret package has several different algorithms for cross-validation but in this chapter we will use the adaptive cross-validation algorithm due to its flexibility. In particular we will use a 10-fold cross-validation (`number = 10`) repeated 3 times (`repeats = 3`) with no grid specified (`search = "random"`), with adaptive parameters set to:

1. 5 minimum resamples used for each tuning parameter (`min = 5`)
2. A confidence level of 0.05 for removing parameter settings (`alpha = 0.05`)
3. A generalized linear model for tuning (`method = "gls"`)
4. The algorithm stops if it finds an optimal solution before the end of resampling (`complete = FALSE`)

We will train three models: a random forest model (`method = "rf"`), a generalized boosted model (`method = "gbm"`), and a supporting vector machine model (`method = "svmRadial"`). The receiver operating characteristic metrics will be used to evaluate models after the training so the metric "ROC" is selected and predictions made during cross-validation are stored in the model object (`metric = "ROC"` in training function and `savePredictions = TRUE` in the train control function).

```{r trainingModels}
# Create data partitions (train set and validation set)
set.seed(1239)
train <- createDataPartition(full.data$y, times = 1, 
                             list = FALSE, p = .8)

# Split data according to partitions
model.train <- full.data[train,]
model.test <- full.data[-train,]

# Define CV procedures
cntr <- trainControl(method = "adaptive_cv",
                     number = 10, repeats = 3,
                     search = "random",
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary,
                     sampling = "up",
                     savePredictions = TRUE,
                     adaptive = list(min = 5, alpha = 0.05, 
                                     method = "gls", 
                                     complete = FALSE))

# Training the models
set.seed(12345)
rf <- train(y ~ ., data = model.train, 
            method = "rf",
            trControl = cntr, tuneLength = 15,
            verbose = FALSE, scale = FALSE,
            metric = "ROC")

set.seed(12345)
gbm <- train(y ~ ., data = model.train, 
             method = "gbm",
             trControl = cntr, tuneLength = 15,
             verbose = FALSE,
             metric = "ROC")

set.seed(12345)
svm <- train(y ~ ., data = model.train, 
             method = "svmRadial",
             trControl = cntr, tuneLength = 15,
             verbose = FALSE, scale = FALSE,
             metric = "ROC")
```

### 3.3 Model evaluation

Since we built classification models based on two classes (also known as binary classifiers) we will evaluate their performances using receiver operating characteristic curves (ROC curves). To do that, we could use the _ad-hoc_ function reported below called `rocCurve` that will extract the best model based on tuned parameters and will produce two ROC curves: one using the same cross validation data (also known as out-of-bag estimates), and the other using the test data. A ROC curve is a graphical representation of the performances of a binary classifier at different threshold settings. Two parameters are displayed in a ROC curve: sensitivity (normally displayed on the y-axis) and specificity (normally displayed on the x-axis). Sensitivity, also called true positive rate, is the proportion of positive observations correctly classified by the model (in this case the proportion of homozygous patients for the $\Delta$F508 mutation correctly classified as such). Specificity, also called "true negative ratio", is the proportion of negative observations correctly classified by the model (in this case the proportion of heterozygous patients for the $\Delta$F508 mutation correctly classified as such). The x-axis of ROC curves is usually inverted unless specificity is replaced by $1 - specificity$ also known as the "false positive rate" (namely the number of negative observations wrongly classified as positives). 

```{r evaluateModel}
model.list <- list(RF = rf,
                   GBM = gbm,
                   SVM = svm)

# ROC curve plotting function
rocCurve <- function(model, data){
  best <- model$bestTune
  pred <- model$pred
  d <- data.frame(pred[,names(best)])
  extr <- apply(d, 1, function(x) all(x == best))
  pred <- pred[extr,]
  
  p <- predict(model, data, type = "prob")
  roc_obj <- roc(data$y, p$heterozygote_F508, 
                 levels = levels(data$y))
  plot.roc(pred$obs, pred$heterozygote_F508)
  plot.roc(roc_obj)
}
```

```{r, echo=F, fig.width=4.5, fig.height=6, fig.cap="Figure 1: Receiver operating characteristic (ROC) curves based on training and test data. The algorithm used to build the models is reported at the top left of each plot (RF, random forest; GBM, generalized boosted model; SVM, supporting vector machine)."}
old <- par(mfrow = c(3, 2), oma=c(0,3,1,0))
invisible(sapply(model.list, rocCurve, model.test))
mtext( 'Train data', side=3, line=-1, at=.28, outer=TRUE, cex=.8, font = 2)
mtext( 'Test data', side=3, line=-1, at=.77, outer=TRUE, cex=.8, font = 2)
mtext( 'RF', side=3, line=-2.9, at=-.04, outer=TRUE, cex=.8, font = 2)
mtext( 'GBM', side=3, line=-18, at=-.03, outer=TRUE, cex=.8, font = 2)
mtext( 'SVM', side=3, line=-32.8, at=-.03, outer=TRUE, cex=.8, font = 2)
par(old)
```

From a first look at the curves reported in Figure 1, random forest and generalized boosted model outperformed supporting vector machines in terms of both sensitivity and specificity on train and test data. To confirm this hypothesis we can calculate the ROC confidence interval at 95% for each model using the function `ci` of the pROC package. The lower, median, and upper values of ROC were reported in Table 1 for all models. Based on results reported, the random tree model is the one with the best performances for classifying the genotype of CF patients based on microbial characteristics.

```{r ciROC, results="asis"}
get_roc <- function(model, data){
  roc_obj <- roc(data$y, 
                 predict(model, data, type = "prob")[,1],
                 levels = levels(model.test$y))
  setNames(as.vector(ci(roc_obj)), 
           c("lower", "ROC", "upper"))
}
roc <- t(sapply(model.list, get_roc, model.test))
```

```{r, echo=F}
knitr::kable(roc, caption="Table 1: Confidence interval of ROC curves reported in Figure 1. Models were reported in the first column whereas the lower, median, and upper values of ROC were reported in the second, third, and fourth column respectively.", digits = 3)
```

## 3.4 Selecting bacterial features

The importance of variables included in the model can be computed in different ways. The caret package provides a series of metrics that can be used in both regression and classification models but, in this chapter, we are going to use a model-related metric called the "Gini coefficient" provided by the randomForest package (`varImp` function of caret package with `useModel = T`). The Gini coefficient is a measure of nodes' "impurity" (or heterogeneity) that ranges from 0 (homogeneous) to 1 (heterogeneous). The mean decrease in Gini coefficient is thus a measure of a variable importance to the classification performances of the model: variables with higher purity cause higher decrease in Gini coefficient. We will extract variable importance from our model to graphically represent their distribution according to type (T for taxa, F for functional, and A for alpha-diversity). Figure 2 shows that 6 gene-related and 4 taxonomic-related variables have an importance higher than the 90% of all variables used to build the model, whereas alpha diversity poorly impacted the model's performances.

```{r featureImp, fig.cap="Figure 2: Importance of varibles used in the model. The importance of each variable was reported according its type: T for taxa, F for functional, and A for alpha-diversity. The red dashed line represent the 90th percentile of the importance distribution.", fig.width=4, fig.height=3}
# Get variables' importance
v.imp <- varImp(model.list$RF, useModel = T,
                scale = F, type = 2)$importance
# Build a data frame for plotting
v.imp <- data.frame(vars = rownames(v.imp),
                    imp = v.imp[[1]],
                    row.names = NULL)
# Get predictor type (the first character)
v.imp$var.type = substr(v.imp$vars, 1, 1)

# Top 10% variables (90th percentile)
top10 <- quantile(v.imp$imp, .9)
top.vars <- as.character(v.imp[v.imp$imp >= top10,"vars"])

# Plotting
figure.2 <- ggplot(v.imp, aes(x = var.type, y = imp)) +
  geom_quasirandom(shape = 1) +
  geom_hline(yintercept = top10,
             linetype = 2,
             color = "red") +
  theme_bw(base_size = 10, base_family = "Helvetica",
           base_line_size = 0.25) +
  xlab("Predictor type") +
  ylab("Mean decrease in Gini coefficient")
figure.2
```

Since we used orthogonal representations of the original microbial features to train our model, we need to extract the contribution of each original feature to the most important variables detected above (Figure 2). To get original contributions we need to calculate their coordinates on principal components (PCs). To do this, we multiply each PC by its standard deviation; then we use resulting coordinates to obtain the representation quality of a variable on a given PC called squared cosine [@herve2010singular]. The relative contribution of a variable can finally be obtained by dividing the squared cosine by its sum over each PC. All these steps are included in a single function called `varContrib`. To finally inspect the contribution of taxa and genes on selected PCs we use the R base function `rowMeans` after selecting top components only (all implemented in the _ad-hoc_ function `formatDataFromContrib`).

```{r varContrib}
varContrib <- function(data.pca){
  # Get coordinates for variables (loadings X standard deviation)
  var.coord <- t(t(data.pca$rotation) * data.pca$sdev)
  # Get quality of representation on the factor map (coordinates^2)
  var.cos2 <- var.coord^2
  # Get variable contributions to the PCs (relative importance)
  t(t((var.cos2*100)) / colSums(var.cos2))
}

# Creates a dataset of variable contributions from a prcomp
# object and a set of selected variables.
formatDataFromContrib <- function(pca, PC.name, top.vars){
  # getting variable contributions
  contrib <- varContrib(pca)
  # change names according to PC.name
  colnames(contrib) <- gsub("PC", PC.name, colnames(contrib))
  # building dataset
  contrib <- rowMeans(contrib[, grep(PC.name, top.vars, value = T)])
  contrib <- sort(contrib, decreasing = T)
  lvls <- names(contrib)
  data.frame(vars = factor(lvls, levels = lvls), contrib = contrib,
             row.names = NULL)
}

# get gene contribution
genes.contrib <- formatDataFromContrib(genes.pca, "F", top.vars)
names(genes.contrib) <- c("best.og", "contrib")

taxa.contrib <- formatDataFromContrib(taxa.pca, "T", top.vars)
names(taxa.contrib) <- c("taxa", "contrib")
```

To inspect how different functional categories contribute to selected PCs we conduct a one-way analysis of variance (ANOVA) using the `aov` function. First, we need to merge gene information to gene contribution using the `merge` function and then we build our model. As shown in Table 2 different COG categories affect the actual contribution of selected PCs with a p-value lower than 0.01.

```{r genesContrib, results="asis"}
# Genes characteristics
meta.genes <- readRDS("data/gene_meta.rds")
meta.genes <- merge(meta.genes, genes.contrib)

# ANOVA
genes.aov <- aov(contrib ~ COG_cat, data = meta.genes)
s <- summary(genes.aov)
```
```{r, results="asis", echo=F}
knitr::kable(s[[1]], caption = "Table 2: Analysis of variance results showing the effect of different COG categories on gene contributions. Df, degrees of freedom; Sum Sq, sum of squares (deviance); Mean Sq, mean square (variance); F value, value of F statistic; Pr(>F), p-value associated to the F statistic.")
```

At this stage we may be interested in which categories have an higher contribution on our model and we can inspect that using the Tukey post-hoc test implemented in the `TukeyHSD` function. The p-values of all the pairways comparisons returned by the function are converted into a character-based encoding using the `multcompLetters` function of the package `multcompView`. Results are then plotted with `ggplot2` (Figure 3).

```{r genesPlot, fig.width=10, fig.height=3, fig.cap="Figure 3: Tukey post-hoc test results. Different COG categories are reported following standard notation. Bars represent the mean contribution for each category whereas error bars represent the upper confidence limit for the observations."}
# Tukey post-hoc test
tuk <- TukeyHSD(genes.aov)

# Converitng p-values into letters
labs <- multcompLetters(tuk$COG_cat[,4])[['Letters']]

# Buidlign data frame
labs <- data.frame(COG_cat = names(labs),
                   labs = labs)
genes.mean <- with(meta.genes, do.call(rbind, by(contrib, COG_cat, mean_cl_boot)))
genes.mean <- data.frame(COG_cat = rownames(genes.mean), genes.mean)
genes.mean$COG_cat <- reorder(genes.mean$COG_cat, genes.mean$y)
genes.mean <- merge(genes.mean, labs)

# Plotting
figure.3 <- ggplot(genes.mean, aes(x = COG_cat, y = y, ymin = ymin, ymax = ymax)) +
  geom_errorbar(width = .3) +
  geom_col() +
  geom_text(aes(label = labs, y = ymax), vjust = -1,
            size = 3) +
  scale_y_continuous(expand = expand_scale(add = c(0,0.0003))) +
  theme_bw(base_size = 10, base_family = "Helvetica",
           base_line_size = 0.25) +
  ylab("Contribution on selected components (%)") +
  xlab("COG categories")
figure.3
```

A similar approach can be applied to taxonomic data by extracting the genus affiliation from species names. This time we will inspect if different genera differentially impact the contribution on selected PCs using the same approach that we used above but with different data. This time differences are not significant (p-value higher than the significance level of 0.05, Table 3) so we will avoid doing any post-hoc test but we will plot the average contribution of each bacterial species to the selected PCs (Figure 4).

```{r, taxaContrib}
# Extracting genus affiliations
genus <- sapply(strsplit(as.character(taxa.contrib$taxa), "_"), "[", 1)
genus <- reorder(factor(genus), taxa.contrib$contrib)

# Adding genera to contribution table
taxa.contrib$genus <- genus

# ANOVA
taxa.aov <- aov(contrib ~ genus, data = taxa.contrib)
s <- summary(taxa.aov)
```

```{r, results="asis", echo=F}
knitr::kable(s[[1]], caption = "Table 3: Analysis of variance results showing the effect of different bacterial genera on taxa contributions. Df, degrees of freedom; Sum Sq, sum of squares (deviance); Mean Sq, mean square (variance); F value, value of F statistic; Pr(>F), p-value associated to the F statistic.")
```

```{r taxaContribPlot, fig.width=6, fig.height=4.5, fig.cap="Figure 4: Average contribution of bacterial species on the selected variables."}
# Mean plotting
figure.4 <- ggplot(taxa.contrib, aes(x = taxa, y = contrib)) +
  geom_col() +
  theme_bw(base_size = 10, base_family = "Helvetica",
           base_line_size = 0.25) +
  scale_y_continuous(expand = expand_scale(add = c(0,0.1))) +
  theme(axis.text.x = element_text(angle=90, hjust = 1, vjust = 0.5)) +
  ylab("Contribution on\nselected components (%)") +
  xlab("Bacterial species")
figure.4
```

```{r savingPlots, echo=F}
# Figure 1
setEPS()
postscript("Figure_1.eps", width = 4.5, height = 6)
old <- par(mfrow = c(3, 2), oma=c(0,3,1,0))
invisible(sapply(model.list, rocCurve, model.test))
mtext( 'Train data', side=3, line=-1, at=.28, outer=TRUE, cex=.8, font = 2)
mtext( 'Test data', side=3, line=-1, at=.77, outer=TRUE, cex=.8, font = 2)
mtext( 'RF', side=3, line=-2.9, at=-.04, outer=TRUE, cex=.8, font = 2)
mtext( 'GBM', side=3, line=-18, at=-.03, outer=TRUE, cex=.8, font = 2)
mtext( 'SVM', side=3, line=-32.8, at=-.03, outer=TRUE, cex=.8, font = 2)
par(old)
dev.off()

# Figure 2
ggsave("Figure_2.eps", figure.2, width = 4, height = 3)

# Figure 3
ggsave("Figure_3.eps", figure.3, width = 10, height = 3)

# Figure 4
ggsave("Figure_4.eps", figure.4, width = 6, height = 4.5)
```


## References