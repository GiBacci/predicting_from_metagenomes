---
title: "Predicting from Metagenomes"
author: "Giovanni Bacci^1^  \n^1^Department of Biology, University of Florence, Via Madonna del Piano 6, Sesto Fiorentino, FI, I-50019, Italy"
output: word_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(ggtree)
library(cowplot)
knitr::opts_chunk$set(echo = TRUE)
```

## Running head

## Summary



```{r importData}
# inporting gene counts
genes <- readRDS("./data/gene_counts.rds")

# inporting antibiotic resistance gene counts
ar.genes <- readRDS("./data/ar_counts.rds")

# inporting proportion of taxa
taxa <- readRDS("./data/taxa_ab.rds")

# sample data
meta <- readRDS("./data/sample_meta.rds")
```

```{r filterData}
# Removing near zero variables
genes.nzv <- nearZeroVar(genes)
ar.genes.nzv <- nearZeroVar(ar.genes)

# Removing taxa present in less than 20% of samples
taxa.filt <- colSums(sign(taxa)) >= (nrow(taxa) * .4)

# Check abundace of excluded variables
nzvRetained <- data.frame(
  genes = rowSums(genes[,-genes.nzv])/rowSums(genes),
  ar.genes = rowSums(ar.genes[,-ar.genes.nzv])/rowSums(ar.genes)
)

nzvRetained %>%
  as_tibble(rownames="samples") %>%
  gather("type", "retained", -samples) %>%
ggplot(aes(x = samples, y = retained)) +
  geom_col() +
  facet_grid(type~.) +
  scale_y_continuous(labels = function(x) round(x*100)) +
  theme_minimal(base_family = "Helvetica",
                base_line_size = 0.25) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, 
                                   vjust = .5, size = 5)) +
  xlab("Samples") +
  ylab("Retained abundace (%)")
```
```{r prepareData}
# PCA analisys on filtered data
genes.pca <- prcomp(genes[,-genes.nzv],
                    center = T, scale. = T)
ar.genes.pca <- prcomp(ar.genes[,-ar.genes.nzv],
                       center = T, scale. = T)

# Dummy variable for patients
subjects <- dummyVars(~ Sample, data = meta)

# Centered log-ratio transformation
taxa <- taxa[,taxa.filt]

# Building full data matrix
genes.X <- genes.pca$x[,genes.pca$sdev^2 >= 1]
ar.genes.X <- ar.genes.pca$x[,ar.genes.pca$sdev^2 >= 1]

colnames(genes.X) <- gsub("PC", "G", colnames(genes.X))
colnames(ar.genes.X) <- gsub("PC", "A", colnames(ar.genes.X))

full.data <- cbind(genes.X, ar.genes.X,
                   predict(subjects, meta))
```

```{r modelling}
cntr <- trainControl(method = "adaptive_cv",
                     number = 10, repeats = 3,
                     search = "random",
                     adaptive = list(min = 5, alpha = 0.05, 
                                     method = "gls", 
                                     complete = FALSE))

library(DESeq2)
genes.vst <- DESeqDataSetFromMatrix(t(genes[,-genes.nzv]), 
                                    colData = meta, design = ~ 1)
genes.vst <- estimateSizeFactors(genes.vst)
genes.vst <- vst(genes.vst)

genes.pca <- prcomp(t(assay(genes.vst)), 
                    center = TRUE, scale. = TRUE)
genes.X <- genes.pca$x[,genes.pca$sdev^2 >= 1]
full.data <- cbind(genes.X, predict(subjects, meta))

modelTaxa <- function(t){
  dataModel <- data.frame(y=t, full.data)
  model <- train(y~., data = dataModel, method = "svmRadial",
                 trControl = cntr, tuneLength = 15,
                 verbose = FALSE, scale = FALSE)
  
  v.imp <- varImp(model, useModel = TRUE, 
                  scale = FALSE)
  v.imp$importance$Overall
}

t <- taxa[,29]
modelTaxaClass <- function(t){
  c <- factor(ifelse(t == 0, 0, 1))
  dataModel <- data.frame(y=c, full.data)
  
  train <- createDataPartition(c, times = 1, 
                               list = FALSE, 
                               p = .9)
  
  model.train <- dataModel[train,]
  model.test <- dataModel[-train,]
  
  model <- train(y ~ ., data = model.train, 
                 method = "lssvmRadial",
                 trControl = cntr, tuneLength = 5,
                 verbose = FALSE, scale = FALSE)
  
  max(model$results$Accuracy)
  
  cbind(model.test$y, predict(model, model.test))
  apply(cbind(model.train$y, predict(model, model.train)), 1, 
        function(x) x[1] == x[2]) %>% sum()
  
  v.imp <- varImp(model, useModel = FALSE, 
                  scale = FALSE)
  v.imp <- varImp(model, scale = FALSE)
  v.imp$importance$X0
  
  colnames(model.train)[-1][2]
}

pc.order <- order(abs(genes.pca$rotation[,2]), decreasing = T)
names(genes.pca$rotation[pc.order, 2][1:10])


imp <- apply(taxa, 2, modelTaxaClass)
rownames(imp) <- colnames(full.data)

gene.meta <- readRDS("./data/gene_meta.rds")
paste0(gene.meta[gene.meta$best.og %in% names(genes.pca$rotation[pc.order, 2][1:20]),"predicted_gene_name"],
       collapse = " ")

```

```{r prepareForPlotting}
imp.dist <- as.dist(1-cor(imp, method="pearson"))
imp.upgma <- hclust(imp.dist, method="complete")

imp.dist.var <- as.dist(1-cor(t(imp), method="pearson"))
imp.upgma.var <- hclust(imp.dist.var, method="complete")

g <- ggtree(imp.upgma) +
  geom_tiplab() +
  scale_x_reverse(expand = c(0,0)) +
  scale_y_continuous(expand = c(0.02, 0))

ord.taxa <- filter(g, isTip) %>% pull(y) %>% order()
ord.var <- imp.upgma.var$order
```
```{r plotting}
d1 <- imp[ord.var, ord.taxa] %>%
  as_tibble(rownames="var") %>%
  gather("taxa", "value", -var) %>%
  mutate_at(c("taxa", "var"), fct_inorder) %>%
  mutate(var.type = str_match(var, "([A-Z])")[,2])

p <- ggplot(d1, aes(x = var, y = taxa, fill = value)) +
  geom_tile() +
  coord_cartesian(expand = F) +
  
  scale_fill_viridis_c(option = "D") +
  facet_grid(.~var.type, scales="free_x", space="free") +
  
  theme_minimal(base_size = 8, base_family = "Helvetica",
                base_line_size = .25) +
  theme(legend.position = "bottom",
        axis.ticks = element_blank(),
        axis.text.x = element_blank(),
        axis.title.y = element_blank(),
        plot.margin = unit(c(0,0,0,0), "lines"))+
  xlab("Variables") +
  guides(fill = guide_colorbar(title = "Importance", 
                               label.position = "bottom",
                               title.position = "top",
                               barwidth = unit(10, "lines"), 
                               barheight = unit(.5, "lines")))

plot_grid(p, g, align = "h", axis = "bt", rel_widths = c(2,1))
```



```{r modelTest, include=FALSE}
counts <- readRDS("~/Dropbox/CF_longitudinal_metagenome/gene_assignments/counts.rds")

c.names <- counts$best.og
counts <- t(counts[,-1])
colnames(counts) <- c.names
rownames(counts) <- gsub("CF_", "", rownames(counts))

library(DESeq2)
dds <- DESeqDataSetFromMatrix(t(counts), colData = sample_data(phylo),
                              design = ~ 1)
dds <- estimateSizeFactors(dds)
dds <- varianceStabilizingTransformation(dds, blind = TRUE, 
                                         fitType = "parametric")
counts.vst <- t(assay(dds))
counts.pca <- prcomp(counts.vst, center = T, scale. = T)
X <- counts.pca$x[,counts.pca$sdev^2 > 1]

taxon <- t(otu_table(phylo))
class(taxon) <- "matrix"
taxon <- ilr(taxon)

library(caret)
library(gbm)
cntr <- trainControl(method = "LOOCV")
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9), 
                        n.trees = (1:10)*50,
                        shrinkage = 0.1,
                        n.minobsinnode = c(1, 3, 5, 7))

zeroFit <- data.frame(y = factor(taxon[,1] != 0), X)
data.train <- createDataPartition(zeroFit$y, p = .8,
                                  list = FALSE, times = 1)
data.test <- zeroFit[-data.train,]
data.train <- zeroFit[data.train,]


data.model <- data.frame(y = taxon[,1], X)
data.train <- createDataPartition(data.model$y, p = .8,
                                  list = FALSE, times = 1)

data.test <- data.model[-data.train,]
data.train <- data.model[data.train,]


model <- train(y~., data = data.train, method = "gbm",
               trControl = cntr, tuneGrid = gbmGrid,
               verbose = FALSE)

data.train$predicted <- predict(model, data.train)
apply(cbind(data.train$predicted, 
            labels = data.train$y), 1, 
      function(x) x[1] == x[2])
test.model <- lm(y ~ predicted, data = data.train)
summary(test.model)

ggplot(model)
varImp(model, useModel = T, scale = T)

# Get coordinates for variables (loadings X standard deviation)
var.coord <- t(t(counts.pca$rotation) * counts.pca$sdev)
# Get quality of representation on the factor map (coordinates^2)
var.cos2 <- var.coord^2
# Get variable contributions to the PCs (relative importance)
var.contrib <- t(t((var.cos2*100)) / colSums(var.cos2))

var.contrib[,"PC34"]
```



## Background

```{r}
library(DESeq2)
library(compositions)
library(caret)


counts <- read.table("data/otutable_corrected.csv", sep = "\t",
                     header = T, row.names = 1)
taxa <- read.table("data/taxonomy_corrected.csv", sep = "\t",
                   header = T, row.names = 1)
meta <- read.table("data/metadata_corrected.csv", sep = "\t",
                   header = T)

counts.round <- round(t(counts))
deseq <- DESeqDataSetFromMatrix(counts.round, colData = meta, 
                                design = ~ provenienza + clumping)
deseq <- estimateSizeFactors(deseq)
deseq <- varianceStabilizingTransformation(deseq, fitType = "parametric")

counts.norm <- assay(deseq)
geo_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}

counts.clr <- apply(t(counts.round), 2, function(x){
  log((x+1)/geo_mean(x))
})

counts.clr[1:10, 1:20]

pca.norm <- prcomp(t(counts.norm), center = T)$x
pca.clt <- prcomp(counts.clr, center = T)$x

pca.clt[,1] <- scales::rescale(pca.clt[,1], to = range(pca.norm[,1]))
pca.clt[,2] <- scales::rescale(pca.clt[,2], to = range(pca.norm[,2]))

pca.norm[,1:2] %>%
  as_tibble() %>%
  mutate(type = "DESeq2") %>%
  rbind(pca.clt[,1:2] %>%
          as_tibble() %>%
          mutate(type = "CLT")) %>%
  mutate(grp = rep(meta$provenienza, 2)) %>%
ggplot(aes(x = PC1, y = PC2, color = type, 
           group = grp, shape = grp)) +
  geom_point() +
  stat_ellipse() +
  scale_x_continuous(sec.axis = sec_axis(~ . /2)) +
  scale_y_continuous(sec.axis = sec_axis(~ . /2))


count.svm <- data.frame(t(counts.norm), 
                        provenienza=meta$provenienza)
trainIndex <- createDataPartition(count.svm$provenienza, 
                                  p = .8, 
                                  list = FALSE, 
                                  times = 1)
train <- count.svm[ trainIndex,]
test  <- count.svm[-trainIndex,]

control <- trainControl(method = "LOOCV")
svm <- train(provenienza~., data=train, method = "rf", 
             trControl = control)
ggplot(svm)


pick_n <- function(n, data, bootstrap = 10){
  if(n < 2)
    return(NULL)
  
  res <- sapply(1:bootstrap, function(i){
    extr <- round(runif(n, min = 1, max = ncol(data)))
    
    counts.sub <- prop.table(as.matrix(data[,extr]), 1)
    counts.sub <- counts.sub[complete.cases(counts.sub),]
    
    rho <- cor(counts.sub, method = "pearson")
    rho[upper.tri(rho)]
  })
  as.vector(res)
}

res <- lapply(2:100, function(n) {
  rho <- pick_n(n = n, data = counts, bootstrap = 10)
  mu <- mean(rho)
  st.err <- sd(rho)/length(rho)
  data.frame(rho = mu, min = mu - st.err, 
             max = mu + st.err, n_var = n)
})
res <- do.call(rbind, res)

nls(rho ~ SSlogis(n_var, Asym, xmid, scal), res)

DNase1 <- subset(DNase, Run == 1)

## using a selfStart model
fm1DNase1 <- nls(density ~ SSlogis(log(conc), Asym, xmid, scal), DNase1)
summary(fm1DNase1)

ggplot(DNase1, aes(x = conc, y = density)) +
  geom_line() +
  

coef(fm1DNase1)



ggplot(res, aes(x = n_var, y = rho)) +
  geom_point()
```

